{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6e1d4f2-b18a-4a7a-8265-0558201ccef6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T07:03:28.562254Z",
     "iopub.status.busy": "2024-06-28T07:03:28.562106Z",
     "iopub.status.idle": "2024-06-28T07:03:29.818386Z",
     "shell.execute_reply": "2024-06-28T07:03:29.818069Z",
     "shell.execute_reply.started": "2024-06-28T07:03:28.562244Z"
    }
   },
   "source": [
    "## Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24ac2549-0cd4-4cfa-b7bc-a34158058710",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T18:58:51.907532Z",
     "iopub.status.busy": "2024-07-10T18:58:51.907376Z",
     "iopub.status.idle": "2024-07-10T18:58:53.335487Z",
     "shell.execute_reply": "2024-07-10T18:58:53.335151Z",
     "shell.execute_reply.started": "2024-07-10T18:58:51.907517Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "import numpy as np\n",
    "import pickle\n",
    "# import evaluate\n",
    "\n",
    "from utils.GLUE_partitaon_dataset import load_partition_glue_data\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import AutoTokenizer, AutoModel, Trainer, TrainingArguments\n",
    "from transformers import RobertaForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding\n",
    "from peft import LoraConfig, get_peft_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f9ac703-176a-46f0-a9c1-8b93bc79f957",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T18:58:53.338497Z",
     "iopub.status.busy": "2024-07-10T18:58:53.338351Z",
     "iopub.status.idle": "2024-07-10T18:59:00.379908Z",
     "shell.execute_reply": "2024-07-10T18:59:00.379621Z",
     "shell.execute_reply.started": "2024-07-10T18:58:53.338490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client 0 \n",
      " train(330) | 1 : 296, 0 : 34 |, valid(271) | 1 : 237, 0 : 34 |, test(313) | 1 : 279, 0 : 34 |\n",
      "client 1 \n",
      " train(330) | 1 : 184, 0 : 146 |, valid(314) | 1 : 184, 0 : 130 |, test(313) | 1 : 184, 0 : 129 |\n",
      "client 2 \n",
      " train(330) | 1 : 50, 0 : 280 |, valid(180) | 1 : 50, 0 : 130 |, test(179) | 1 : 50, 0 : 129 |\n",
      "client 3 \n",
      " train(330) | 1 : 330, 0 : 0 |, valid(237) | 1 : 237, 0 : 0 |, test(279) | 1 : 279, 0 : 0 |\n",
      "client 4 \n",
      " train(330) | 1 : 113, 0 : 217 |, valid(243) | 1 : 113, 0 : 130 |, test(242) | 1 : 113, 0 : 129 |\n",
      "client 5 \n",
      " train(330) | 1 : 330, 0 : 0 |, valid(237) | 1 : 237, 0 : 0 |, test(279) | 1 : 279, 0 : 0 |\n",
      "client 6 \n",
      " train(330) | 1 : 2, 0 : 328 |, valid(132) | 1 : 2, 0 : 130 |, test(131) | 1 : 2, 0 : 129 |\n",
      "client 7 \n",
      " train(330) | 1 : 271, 0 : 59 |, valid(296) | 1 : 237, 0 : 59 |, test(330) | 1 : 271, 0 : 59 |\n",
      "client 8 \n",
      " train(330) | 1 : 330, 0 : 0 |, valid(237) | 1 : 237, 0 : 0 |, test(279) | 1 : 279, 0 : 0 |\n",
      "client 9 \n",
      " train(331) | 1 : 331, 0 : 0 |, valid(237) | 1 : 237, 0 : 0 |, test(279) | 1 : 279, 0 : 0 |\n"
     ]
    }
   ],
   "source": [
    "client_num = 10\n",
    "alpha = 1.0\n",
    "data = \"mrpc\"\n",
    "client_datasets, tokenized_datasets = load_partition_glue_data(data, client_num, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d98c0e6e-f4fb-4c3c-9cf2-0641b6045065",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T19:21:58.966524Z",
     "iopub.status.busy": "2024-07-10T19:21:58.966309Z",
     "iopub.status.idle": "2024-07-10T19:21:59.108472Z",
     "shell.execute_reply": "2024-07-10T19:21:59.108179Z",
     "shell.execute_reply.started": "2024-07-10T19:21:58.966501Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haken/.conda/envs/fedllm-v2/lib/python3.9/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"./llm_models/FL/\"\n",
    "# Ë®≠ÁΩÆ LoRA ÈÖçÁΩÆ\n",
    "lora_config = LoraConfig(\n",
    "    r=16,  # Rank\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "# Ë®ìÁ∑¥ÂèÉÊï∏Ë®≠ÁΩÆ\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=save_dir,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e7db5dae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T19:21:59.620857Z",
     "iopub.status.busy": "2024-07-10T19:21:59.620641Z",
     "iopub.status.idle": "2024-07-10T19:22:00.529000Z",
     "shell.execute_reply": "2024-07-10T19:22:00.528631Z",
     "shell.execute_reply.started": "2024-07-10T19:21:59.620844Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2)\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "peft_model = get_peft_model(model, lora_config)\n",
    "client_models = [copy.deepcopy(peft_model) for idx in range(client_num)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "700f81da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T19:22:00.620556Z",
     "iopub.status.busy": "2024-07-10T19:22:00.620411Z",
     "iopub.status.idle": "2024-07-10T19:22:00.661783Z",
     "shell.execute_reply": "2024-07-10T19:22:00.661519Z",
     "shell.execute_reply.started": "2024-07-10T19:22:00.620538Z"
    }
   },
   "outputs": [],
   "source": [
    "# ÂàùÂßãÂåñ GPT-2 ÁöÑ tokenizer ‰∏¶Ë®≠ÁΩÆ padding token\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./llm_models/roberta_base\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "22c4a263-8090-4841-a03b-bd0dc4bc1ab4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T19:22:06.780893Z",
     "iopub.status.busy": "2024-07-10T19:22:06.780672Z",
     "iopub.status.idle": "2024-07-10T19:22:38.980187Z",
     "shell.execute_reply": "2024-07-10T19:22:38.979948Z",
     "shell.execute_reply.started": "2024-07-10T19:22:06.780876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='110' max='110' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [110/110 00:31, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=110, training_loss=0.667858193137429, metrics={'train_runtime': 31.6469, 'train_samples_per_second': 104.276, 'train_steps_per_second': 3.476, 'total_flos': 132764709990264.0, 'train_loss': 0.667858193137429, 'epoch': 10.0})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=client_datasets[0][\"train\"],\n",
    "    eval_dataset=client_datasets[0][\"valid\"],\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bdb83bdf-a3b3-46f2-add8-d19002b47d07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T19:23:39.816175Z",
     "iopub.status.busy": "2024-07-10T19:23:39.815985Z",
     "iopub.status.idle": "2024-07-10T19:23:39.818494Z",
     "shell.execute_reply": "2024-07-10T19:23:39.818169Z",
     "shell.execute_reply.started": "2024-07-10T19:23:39.816163Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_acc(trainer, test_data):\n",
    "    \n",
    "    accuracy_metric = load_metric(\"accuracy\")\n",
    "    predictions = trainer.predict(test_data)\n",
    "    pred = np.argmax(predictions.predictions[1], axis=-1)\n",
    "    accuracy = accuracy_metric.compute(predictions=pred, references=test_data[\"labels\"])\n",
    "    return accuracy, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "34697651-48d8-4433-ab98-f8b984612c32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T19:23:41.151146Z",
     "iopub.status.busy": "2024-07-10T19:23:41.150949Z",
     "iopub.status.idle": "2024-07-10T19:23:43.287588Z",
     "shell.execute_reply": "2024-07-10T19:23:43.287368Z",
     "shell.execute_reply.started": "2024-07-10T19:23:41.151133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8913738019169329}\n"
     ]
    }
   ],
   "source": [
    "acc, pred = predict_acc(trainer, client_datasets[0][\"test\"])\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5eb201-ac6c-4d81-a748-46f9096d7ab2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf8bb47d-5ea6-42c8-97d6-593b49f8f49f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T18:54:47.184613Z",
     "iopub.status.busy": "2024-07-10T18:54:47.184414Z",
     "iopub.status.idle": "2024-07-10T18:54:52.586538Z",
     "shell.execute_reply": "2024-07-10T18:54:52.586132Z",
     "shell.execute_reply.started": "2024-07-10T18:54:47.184600Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dataset does not contain an 'id' column",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Ê£ÄÊü•Êï∞ÊçÆÈõÜÊòØÂê¶Êúâ 'id' Âàó\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcolumn_names:\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset does not contain an \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m column\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Ëá™ÂÆö‰πâ ID\u001b[39;00m\n\u001b[1;32m     12\u001b[0m custom_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: Dataset does not contain an 'id' column"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "import numpy as np\n",
    "\n",
    "# Âä†ËΩΩÊï∞ÊçÆÈõÜ\n",
    "dataset = load_dataset(\"glue\", \"mrpc\")\n",
    "\n",
    "# Ê£ÄÊü•Êï∞ÊçÆÈõÜÊòØÂê¶Êúâ 'id' Âàó\n",
    "if 'id' not in dataset['train'].column_names:\n",
    "    raise ValueError(\"Dataset does not contain an 'id' column\")\n",
    "\n",
    "# Ëá™ÂÆö‰πâ ID\n",
    "custom_ids = list(dataset['train']['id'])\n",
    "np.random.shuffle(custom_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e85fbd-9f40-49b4-8bbe-2ccb4f622ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Â∞ÜÊï∞ÊçÆÈõÜÂàÜÊàê 5 ‰ªΩ\n",
    "n_splits = 5\n",
    "split_datasets = []\n",
    "split_size = len(custom_ids) // n_splits\n",
    "\n",
    "for i in range(n_splits):\n",
    "    split_ids = custom_ids[i * split_size: (i + 1) * split_size]\n",
    "    split_dataset = dataset['train'].filter(lambda example: example['id'] in split_ids)\n",
    "    split_datasets.append(split_dataset)\n",
    "\n",
    "# Â∞ÜÂàÜÂâ≤ÁöÑÊï∞ÊçÆÈõÜËΩ¨Êç¢‰∏∫ DatasetDict\n",
    "split_dataset_dict = DatasetDict({\n",
    "    f'train_split_{i}': split_datasets[i] for i in range(n_splits)\n",
    "})\n",
    "\n",
    "# ÊâìÂç∞ÊØè‰∏™ÂàÜÂâ≤ÁöÑÊï∞ÊçÆÈõÜÂ§ßÂ∞è\n",
    "for i in range(n_splits):\n",
    "    print(f\"train_split_{i} size: {len(split_dataset_dict[f'train_split_{i}'])}\")\n",
    "\n",
    "# Á§∫‰æãÔºöËÆ≠ÁªÉÁ¨¨‰∏Ä‰∏™ÂàÜÂâ≤ÁöÑÊï∞ÊçÆÈõÜ\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# Âä†ËΩΩ tokenizer ÂíåÊ®°Âûã\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "\n",
    "# Tokenize Êï∞ÊçÆÈõÜ\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['sentence1'], examples['sentence2'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = split_dataset_dict.map(tokenize_function, batched=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f591a95-0a5d-4878-9d36-daa611e171e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ËÆæÁΩÆËÆ≠ÁªÉÂèÇÊï∞\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "# ÂÆö‰πâ Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train_split_0'],\n",
    "    eval_dataset=tokenized_datasets['train_split_1']\n",
    ")\n",
    "\n",
    "# ËÆ≠ÁªÉÊ®°Âûã\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-fedllm-v2]",
   "language": "python",
   "name": "conda-env-.conda-fedllm-v2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
